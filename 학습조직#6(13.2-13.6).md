# 학습조직#6(13.2-13.6)

### 13.2 TFRecord Format

csv 파일로 데이터를 불러오는 것이 불가능 할때, 혹은 데이터셋이 너무 방대할때 사용하는 데이터 포맷으로, TF 함수들을 통해 간편하게 사용 가능함. 

- TFRecord writing 할 때의 작업 순서
  - csv에서 데이터셋을 읽어온다. 
  - 각 인스턴스마다 예시 프로토콜 버퍼를(protocal buffer) 생성한다. 
  - 데이터셋을 직렬화(serialize) 한다.
  - 셔플링 하여 TFRecord로 저장한다. 
- TFRecord loading/parsing 할 때의 작업 순서
  - TFRecord의 내부의 데이터 설명을 정의한다. 
  - TFRecord의 각 배치로부터 데이터를 읽어온다. 
  - 각 배치마다 데이터 파싱을 진행한다.

### 13.3 Preprocessing Input Features

범주형 변수를 수치형으로 변환하거나, 정규화를 진행하거나 하는 일련의 과정을 총칭. map() 이나 lambda() 함수 등 파이썬 내장 함수를 사용해서도 간단하게 진행 할 수 있으나, TF 함수를 통해서도 전처리를 할 수 있음. 

- 원 핫 인코딩(one-hot-encoding)

  범주의 개수가 10개 이내일 때 사용 할 것을 권장함. (너무 많은 범주에 대해서는 적절치 않음.)

  - 수치형으로 변환할 카테고리 변수의 index를 찾는 테이블을 생성한다.

    ```python
    table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)
    categories = tf.constant(["NEAR BAY", "DESERT", "INLAND", "INLAND"])
    cat_indices = table.lookup(categories)
    ```

  - `tf.one_hot(cat_indicies, depth=...)`함수를 사용하여 원핫인코딩을 진행한다. 

  

- Embedding 을 사용한 인코딩

  범주의 개수가 많을 때 주로 사용하는 인코딩 방식.

  ==word embedding== 이란?

  일반적인 벡터화 + 원핫 인코딩을 사용해서 각 단어에 고유 벡터를 부여 할 수는 있으나, 해당 백터화 방법은 단어의 중요도나 문서 안에서의 중요도는 구분 할 수 있으나 단어 사이의 유사도는 구별 할 수 없다는 단점을 지니고 있음. 

  -> 이때 단어 사이의 유사도를 구별하기 위해 사용하는 것이 word embedding 임

  의미가 유사한 단어들은 서로 가깝게 뿌려지고, 의미가 상이한 단어들은 서로 멀게 n 차원상에 embedding됨. 

  word embedding 은 다음과 같은 종류가 있음.

  1) 행렬 분해

     Corpus 정보가 들어 있는 원래 행렬을 Decomposition을 통해 임베딩 하는 기법으로, Decomposition 이후엔 둘 중 하나의 행렬만 사용하거나 둘을 sum하거나 concatenate하는 방식으로 임베딩을 진행.

     ex) GloVe, Swivel 등

  2) 예측 기반

     어떤 단어 주변에 특정 단어가 나타날지 예측하거나, 이전 단어들이 주어졌을 때 다음 단어가 무엇일지 예측하거나, 문장 내 일부 단어를 지우고 해당 단어가 무엇일지 맞추는 과정에서 학습하는 방법

     Neural Network기반 방법들이 속한다. ex) Word2Vec, FastText, BERT, ELMo, GPT 등

  3) 토픽 기반

     주어진 문서에 잠재된 주제를 추론하는 방식으로 임베딩을 수행하는 기법이며, 대표적으로 잠재 디리클레 할당(LDA) 가 있음. LDA 같은 모델은 학습이 완료되면 각 문서가 어떤 주제 분포를 갖는지 확률 벡터 형태로 반환하기 때문에 임베딩 기법의 일종으로 구분 할 수 있음. 

### 13.4 TF transformation

텐서플로 모델 상품화를 위한 end to end 플랫폼인 TFX의 일부분으로, 전처리 연산을 딱 한번만 정의하면 되기 때문에 빠르고 효율적임. (TFX를 설치 한 후 사용 가능함)



